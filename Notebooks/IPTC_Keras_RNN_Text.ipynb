{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IPTC_Keras_RNN_Text.ipynb","version":"0.3.2","provenance":[{"file_id":"1ossNQSrXyvkmF7ZvZr7QPryk49A9tpCX","timestamp":1521206578358}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dUNKDytx2E6E","colab_type":"text"},"source":["## Text Prediction/Generation with Keras using <font color= #13c113  >LSTM: *Long Short Term Memory* networks</font>\n","\n","    In this example we will work with the book: Alice’s Adventures in Wonderland by Lewis Carroll.\n","\n","    We are going to learn the dependencies between characters and the conditional probabilities of characters in sequences so that we can in turn generate wholly new and original sequences of characters.\n","    \n","![Text-Generation-With-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/08/Text-Generation-With-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras.jpg)\n","\n","\n","### Adapted from:\n","#### [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n","\n","By Jason Brownlee\n","\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"FsnDWHL0sYVC","colab_type":"text"},"source":["<img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" alt=\"Keras logo\" height=\"100\" width=\"250\"> \n","\n","---\n","\n","<font size=4 >Summer Seminar:</font> <font size=4 color= orange>Practical Introduction to Deep Learning & Keras</font>\n","\n"," <img src=\"https://pbs.twimg.com/profile_images/969243109208018946/w2GzDfiC_400x400.jpg\" alt=\"IPTC\" height=\"50\" width=\"50\"> \n"," ## * [IPTC](https://iptc.upm.es/) and [MSTC](http://mstc.ssr.upm.es/big-data-track)\n"," \n","---\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"d7BYb9WvopbE","colab_type":"text"},"source":["\n","\n","---\n","\n","## Start installing some libraries do some imports..."]},{"cell_type":"code","metadata":{"id":"6UFqWyqn2E6P","colab_type":"code","outputId":"f7744c02-ae55-4d73-c401-f617b7b434bc","executionInfo":{"status":"ok","timestamp":1563361591244,"user_tz":-120,"elapsed":1714,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","\n","import keras\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"odDMNWMpVwpI","colab_type":"text"},"source":["\n","\n","---\n","\n","## Down load TEXT file <font color= #2a9dad >*Alice’s Adventures in Wonderland*</font>"]},{"cell_type":"markdown","metadata":{"id":"8BoeyLdlAMFk","colab_type":"text"},"source":["- ### We will first download the complete text in ASCII format (Plain Text UTF-8) \n","\n","- #### [Project Gutenberg](https://www.gutenberg.org/): gives free access to books that are no longer protected by copyright\n","\n","- ### Text has been prepared in a Google Drive link\n","\n"]},{"cell_type":"code","metadata":{"id":"wVLz9hSvmsiC","colab_type":"code","outputId":"dd209bbc-6854-441c-bb1f-2d5f102e30f5","executionInfo":{"status":"ok","timestamp":1563361601605,"user_tz":-120,"elapsed":3970,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["! pip install googledrivedownloader"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Db_o1gvImUm6","colab_type":"code","outputId":"88489767-7a9c-48bd-b1c1-acca044a2f90","executionInfo":{"status":"ok","timestamp":1563361698792,"user_tz":-120,"elapsed":1036,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","gdd.download_file_from_google_drive(file_id='1wG4PUnoYVUKrsaWgyWepSacUiYNNDEvM',\n","                                    dest_path='./wonderland.txt',\n","                                    unzip=False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading 1wG4PUnoYVUKrsaWgyWepSacUiYNNDEvM into ./wonderland.txt... Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jex6dqRlWsKQ","colab_type":"text"},"source":["- ### Read text for the book and convert all of the characters to lowercase to reduce the vocabulary that the network must learn"]},{"cell_type":"code","metadata":{"id":"R2IU6TLHWky6","colab_type":"code","colab":{}},"source":["# load ascii text and covert to lowercase\n","filename = \"wonderland.txt\"\n","raw_text = open(filename).read()\n","raw_text = raw_text.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6_VWNBKa2ku","colab_type":"code","outputId":"7faa91ed-e672-413c-e2fb-ff8d5763f917","executionInfo":{"status":"ok","timestamp":1563361705464,"user_tz":-120,"elapsed":461,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":253}},"source":["print(raw_text[0:200])\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["alice's adventures in wonderland\n","\n","lewis carroll\n","\n","the millennium fulcrum edition 3.0\n","\n","\n","\n","\n","chapter i. down the rabbit-hole\n","\n","alice was beginning to get very tired of sitting by her sister on the\n","bank, and\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J7ZPLsFQXGCE","colab_type":"text"},"source":["- ### We must use a \"numerical\" representation of text characters directly,\n","- ### We will start using a simple one: $integers$\n","- ### (Some characters could have been removed to further clean up the text)"]},{"cell_type":"markdown","metadata":{"id":"F-HDPTBJZuDP","colab_type":"text"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","How many different characters in raw_text?  store then ordered in a list</font>"]},{"cell_type":"code","metadata":{"id":"ss0TJIsyaKYg","colab_type":"code","outputId":"941faadf-4189-4fa9-a3b5-fc29934c4b79","executionInfo":{"status":"ok","timestamp":1563361716619,"user_tz":-120,"elapsed":442,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["chars = sorted(list(set(raw_text)))\n","\n","print(chars)\n","print('Number of characters: ',len(chars))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '3', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","Number of characters:  45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IojHeJjubjiy","colab_type":"text"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","MAP each character to an integer using a Python *dictionary*  with key(char) : value(int) </font>"]},{"cell_type":"code","metadata":{"id":"z3LONt7Ub3zt","colab_type":"code","colab":{}},"source":["char_to_int = dict((c, i) for i, c in enumerate(chars))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QG_-e37heJhl","colab_type":"code","outputId":"192c4824-5bf7-4973-916d-af80ec2c4914","executionInfo":{"status":"ok","timestamp":1563361721852,"user_tz":-120,"elapsed":453,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["char_to_int['z']"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QGakftCBeVdO"},"source":["<font color=yellow face=\"times, serif\" size=5>============================================<br>\n","INVERSE MAP: get the char from an integer using a *dictionary*  int: char </font>"]},{"cell_type":"code","metadata":{"id":"ByLYr2_5W5rG","colab_type":"code","colab":{}},"source":["int_to_char = dict((i, c) for i, c in enumerate(chars))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1LxL5F9fWZo","colab_type":"code","outputId":"5f4ad4e0-28f1-4177-a810-abed6259da2b","executionInfo":{"status":"ok","timestamp":1563361725835,"user_tz":-120,"elapsed":422,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["int_to_char[44]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'z'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"rggkUQX7fP6j","colab_type":"code","outputId":"391658ff-821c-4bf1-c18e-f8ae16eb99a1","executionInfo":{"status":"ok","timestamp":1563361729269,"user_tz":-120,"elapsed":477,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"Total Characters: \", n_chars)\n","print(\"Total Vocab: \", n_vocab)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Total Characters:  144431\n","Total Vocab:  45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bt8y8RI2t7c0","colab_type":"text"},"source":["---\n","\n","## Prediction Task:\n","\n","\n","- ### <font color=red> Number of steps</font>: We will split the book text up into subsequences with a <font color=red>fixed length of 100 characters, an arbitrary length</font>. \n","\n","- ### To train the network we slide a windows of seq_length = 100 characters along the whole book\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"38qvEI_bhSaq"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","**Slide a window extracting a sequence of seq_length = 100 characters along the book and store it in dataX : the input to the network</font>"]},{"cell_type":"code","metadata":{"id":"O25hAvcYhfii","colab_type":"code","colab":{}},"source":["seq_length = 100\n","\n","dataX=[]\n","\n","for i in range(0, n_chars - seq_length, 1):\n","  seq_in = raw_text[i:i+seq_length]\n","  dataX.append(seq_in)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HeTJAgJzijQQ","colab_type":"code","outputId":"8eaf090d-7a6a-4fe9-c040-f2b5ad5c8ffd","executionInfo":{"status":"ok","timestamp":1563361741768,"user_tz":-120,"elapsed":456,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["print('dataX length: ',len(dataX))\n","print('dataX first training example: \\n',dataX[0])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["dataX length:  144331\n","dataX first training example: \n"," alice's adventures in wonderland\n","\n","lewis carroll\n","\n","the millennium fulcrum edition 3.0\n","\n","\n","\n","\n","chapter i. d\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fpanFsYCjFWv"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","dataX MUST be numeric!!! make changes using our $char\\_to\\_int$ dictionary</font>"]},{"cell_type":"code","metadata":{"id":"KMlzbpf8jZcf","colab_type":"code","colab":{}},"source":["seq_length = 100\n","\n","dataX=[]\n","\n","for i in range(0, n_chars - seq_length, 1):\n","  seq_in = raw_text[i:i+seq_length]\n","  dataX.append([char_to_int[char] for char in seq_in])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzXntZ6KkgTP","colab_type":"code","outputId":"3687c934-cb18-44c0-fe4d-135ec4747398","executionInfo":{"status":"ok","timestamp":1563361754316,"user_tz":-120,"elapsed":1187,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["print('dataX length: ',len(dataX))\n","print('dataX first training example: \\n',dataX[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["dataX length:  144331\n","dataX first training example: \n"," [19, 30, 27, 21, 23, 4, 37, 1, 19, 22, 40, 23, 32, 38, 39, 36, 23, 37, 1, 27, 32, 1, 41, 33, 32, 22, 23, 36, 30, 19, 32, 22, 0, 0, 30, 23, 41, 27, 37, 1, 21, 19, 36, 36, 33, 30, 30, 0, 0, 38, 26, 23, 1, 31, 27, 30, 30, 23, 32, 32, 27, 39, 31, 1, 24, 39, 30, 21, 36, 39, 31, 1, 23, 22, 27, 38, 27, 33, 32, 1, 12, 10, 11, 0, 0, 0, 0, 0, 21, 26, 19, 34, 38, 23, 36, 1, 27, 10, 1, 22]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T0_kYn0DlCUM"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","Now we have to create the output for each 100 characters windows: </font>\n","  - the OUTPUT will be the next character, that is: we will train to predict the next character after \"seeing\" 100 previous characters. </font>\n","  \n","###So add to the for loop some code to store the \"next character\" for each window in dataY  :  again this MUST be numeric!!! so use our $char\\_to\\_int$ dictionary</font>"]},{"cell_type":"code","metadata":{"id":"ypvND-9uvG4g","colab_type":"code","colab":{}},"source":["\n","seq_length = 100\n","\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","  \n","\tseq_in = raw_text[i:i + seq_length]\n","\tseq_out = raw_text[i + seq_length]\n","\tdataX.append([char_to_int[char] for char in seq_in])\n","\tdataY.append(char_to_int[seq_out])\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqguLk9umLdU","colab_type":"code","outputId":"5f45248f-c70c-4c63-a004-fe231c90b4da","executionInfo":{"status":"ok","timestamp":1563361764577,"user_tz":-120,"elapsed":1411,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["n_patterns = len(dataX)\n","\n","print(\"Total Patterns: \", n_patterns)\n","print(\"Pattern shape: \",np.array(dataX).shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Total Patterns:  144331\n","Pattern shape:  (144331, 100)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gTPm6IwV0D7S","colab_type":"text"},"source":["- ### Let's see two examples:"]},{"cell_type":"code","metadata":{"id":"dNI1LWe8xOrI","colab_type":"code","outputId":"eee0fefb-1de8-4ac8-9f63-45d9b90e9ffd","executionInfo":{"status":"ok","timestamp":1563361766773,"user_tz":-120,"elapsed":439,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":344}},"source":["print(\"------Window input dataX -------------------------------------\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in dataX[201]]), \"\\\"\")\n","print(\"\\n -----Character to predict dataY:\")\n","print(\"\\\"\", int_to_char[dataY[201]])\n","print(\"\\n\")\n","print(\"------Window input dataX -------------------------------------\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in dataX[202]]), \"\\\"\")\n","print(\"\\n -----Character to predict dataY:\")\n","print(\"\\\"\", int_to_char[dataY[202]])\n","print(\"\\n\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in dataY[100:216]]), \"\\\"\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["------Window input dataX -------------------------------------\n","\" of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it h \"\n","\n"," -----Character to predict dataY:\n","\" a\n","\n","\n","------Window input dataX -------------------------------------\n","\" f having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it ha \"\n","\n"," -----Character to predict dataY:\n","\" d\n","\n","\n","\"  of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it had no pictures  \"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uDwrt7he0aIi","colab_type":"text"},"source":["\n","\n","---\n","\n","## We must now prepare our training data to be suitable for use with LSTM in Keras.\n","\n","- ### First we must transform the list of input sequences into the form <font color= #3498db>  [no. samples or batches, time steps, features]</font> expected by an LSTM network. <font color=red> NOTE that our number of features is 1</font>\n","\n","- ### Next we need to rescale the integers to the range 0-to-1 to make the patterns easier to learn by the LSTM network that uses the sigmoid activation function by default.\n","\n","- ### Finally, we need to convert the output patterns (single characters converted to integers) into a one hot encoding: to predict the probability of each of the different characters in the vocabulary"]},{"cell_type":"code","metadata":{"id":"Vnokv8nkpChv","colab_type":"code","outputId":"23f27e51-e0e3-47e8-994b-513cec81adb2","executionInfo":{"status":"ok","timestamp":1563361812703,"user_tz":-120,"elapsed":1335,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print('dataX shape', np.array(dataX).shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["dataX shape (144331, 100)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lk372vY7wLBw","colab_type":"code","colab":{}},"source":["# reshape X to be [samples, time steps, features]\n","X = np.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalize\n","X = X / float(n_vocab)\n","# one hot encode the output variable\n","y = np_utils.to_categorical(dataY)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxOMpiTMpp2P","colab_type":"code","outputId":"219b056a-3415-405c-c257-41e696d24ace","executionInfo":{"status":"ok","timestamp":1563361818175,"user_tz":-120,"elapsed":427,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["# or with keras\n","ykeras=keras.utils.to_categorical(dataY)\n","\n","print('OHE example numpy',y[3])\n","print('OHE example keras',ykeras[3])\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["OHE example numpy [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","OHE example keras [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QsAh3_py0Ywy","colab_type":"code","outputId":"52cf68db-02c5-41c5-f6b5-26b49598a019","executionInfo":{"status":"ok","timestamp":1521656924780,"user_tz":-60,"elapsed":704,"user":{"displayName":"Luis Hernandez Gomez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114480253738065527469"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["X[200,0:10]*n_vocab"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.],\n","       [33.],\n","       [24.],\n","       [ 1.],\n","       [26.],\n","       [19.],\n","       [40.],\n","       [27.],\n","       [32.],\n","       [25.]])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"muyhcmH_qUfR","colab_type":"text"},"source":["## NOTE that to go now -after normalization- from int to chat we must multiply by n_vocab and round to integer "]},{"cell_type":"code","metadata":{"id":"vddjIgIp1_MM","colab_type":"code","outputId":"2398984c-225c-4aee-98e2-6257a9bc584c","executionInfo":{"status":"ok","timestamp":1563361831933,"user_tz":-120,"elapsed":437,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["print(\"\\\"\", ''.join([int_to_char[int(value+0.5)] for value in X[200,:]*n_vocab]), \"\\\"\")\n","print(\"\\\"\", ''.join([int_to_char[int(value)] for value in dataX[200]]), \"\\\"\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\"  of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it  \"\n","\"  of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it  \"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F-4PJkMKL6qs","colab_type":"text"},"source":["---\n","## We can now define and compile our LSTM model:\n","- ### Here we define a single hidden LSTM layer with 256 memory units.\n","- ### The network uses dropout with a probability of 20.\n","- ### The output layer is a Dense layer using the softmax activation function to output a probability prediction for each of the possible characters between 0 and 1.\n","\n"]},{"cell_type":"code","metadata":{"id":"fs5ggo7a88ZK","colab_type":"code","outputId":"a07d34f0-1852-4c1a-d909-fc292d67748c","executionInfo":{"status":"ok","timestamp":1563361847919,"user_tz":-120,"elapsed":447,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["print('X shape: ', X.shape)\n","print('y.shape: ',y.shape)\n","y[0,:]"],"execution_count":23,"outputs":[{"output_type":"stream","text":["X shape:  (144331, 100, 1)\n","y.shape:  (144331, 45)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZEj8EzCZq56I"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","Define the LSTM model using Sequential style. </font>\n"," "]},{"cell_type":"code","metadata":{"id":"9WThZ_vs2L_W","colab_type":"code","outputId":"8fd4a84b-a468-404a-baab-9aa15e1db591","executionInfo":{"status":"ok","timestamp":1563361896810,"user_tz":-120,"elapsed":1068,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","model.summary()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0717 11:11:34.996115 140291906377600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0717 11:11:35.041148 140291906377600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0717 11:11:35.048360 140291906377600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0717 11:11:35.622599 140291906377600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0717 11:11:35.633862 140291906377600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0717 11:11:35.661968 140291906377600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0717 11:11:35.682997 140291906377600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_1 (LSTM)                (None, 256)               264192    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 45)                11565     \n","=================================================================\n","Total params: 275,757\n","Trainable params: 275,757\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LL5DlcUmNWpQ","colab_type":"text"},"source":["- ### Note that we not really are interested in prediction\n","- ### We are seeking a balance between generalization and overfitting but short of memorization.\n","- ### Because of the slowness of our optimization requirements, we will use model checkpointing to record all of the network weights to file each time an improvement in loss is observed at the end of the epoch.\n","- ### We will use the best set of weights (lowest loss) to instantiate our generative model in the next section."]},{"cell_type":"markdown","metadata":{"id":"a9Y67_F_rn8C","colab_type":"text"},"source":["## <font color=orange> Take a look to hdf5 !!!</font>\n","\n","    HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. HDF5 is portable and is extensible, allowing applications to evolve in their use of HDF5. The HDF5 Technology suite includes tools and applications for managing, manipulating, viewing, and analyzing data in the HDF5 format.\n","\n","## [HDF5 Web portal](https://portal.hdfgroup.org/display/HDF5/HDF5)"]},{"cell_type":"code","metadata":{"id":"HjQRFIXQMyzw","colab_type":"code","colab":{}},"source":["# define the checkpoint\n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"almMRAEOOQdq","colab_type":"text"},"source":["---\n","\n","## Fit our model to the data.\n","- ### Here we use a modest number of 20 epochs and a large batch size of 128 pattern"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PWBd0kFOspoJ"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","**TO DO:**   Fit the model, first with 20 epochs batch_size=128 AND $callbacks$ !! </font>\n"," "]},{"cell_type":"code","metadata":{"id":"rvJOEfLBOgJ8","colab_type":"code","outputId":"e5fac090-671d-4cec-8bc6-5f98a9783812","executionInfo":{"status":"ok","timestamp":1563365358073,"user_tz":-120,"elapsed":3129966,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","144331/144331 [==============================] - 154s 1ms/step - loss: 2.7289\n","\n","Epoch 00001: loss improved from 2.95907 to 2.72892, saving model to weights-improvement-01-2.7289.hdf5\n","Epoch 2/20\n","144331/144331 [==============================] - 156s 1ms/step - loss: 2.6309\n","\n","Epoch 00002: loss improved from 2.72892 to 2.63085, saving model to weights-improvement-02-2.6309.hdf5\n","Epoch 3/20\n","144331/144331 [==============================] - 159s 1ms/step - loss: 2.5592\n","\n","Epoch 00003: loss improved from 2.63085 to 2.55923, saving model to weights-improvement-03-2.5592.hdf5\n","Epoch 4/20\n","144331/144331 [==============================] - 155s 1ms/step - loss: 2.4963\n","\n","Epoch 00004: loss improved from 2.55923 to 2.49625, saving model to weights-improvement-04-2.4963.hdf5\n","Epoch 5/20\n","144331/144331 [==============================] - 156s 1ms/step - loss: 2.4403\n","\n","Epoch 00005: loss improved from 2.49625 to 2.44027, saving model to weights-improvement-05-2.4403.hdf5\n","Epoch 6/20\n","144331/144331 [==============================] - 157s 1ms/step - loss: 2.3864\n","\n","Epoch 00006: loss improved from 2.44027 to 2.38637, saving model to weights-improvement-06-2.3864.hdf5\n","Epoch 7/20\n","144331/144331 [==============================] - 155s 1ms/step - loss: 2.3367\n","\n","Epoch 00007: loss improved from 2.38637 to 2.33672, saving model to weights-improvement-07-2.3367.hdf5\n","Epoch 8/20\n","144331/144331 [==============================] - 155s 1ms/step - loss: 2.2909\n","\n","Epoch 00008: loss improved from 2.33672 to 2.29089, saving model to weights-improvement-08-2.2909.hdf5\n","Epoch 9/20\n","144331/144331 [==============================] - 156s 1ms/step - loss: 2.2438\n","\n","Epoch 00009: loss improved from 2.29089 to 2.24384, saving model to weights-improvement-09-2.2438.hdf5\n","Epoch 10/20\n","144331/144331 [==============================] - 158s 1ms/step - loss: 2.1998\n","\n","Epoch 00010: loss improved from 2.24384 to 2.19985, saving model to weights-improvement-10-2.1998.hdf5\n","Epoch 11/20\n","144331/144331 [==============================] - 157s 1ms/step - loss: 2.1606\n","\n","Epoch 00011: loss improved from 2.19985 to 2.16059, saving model to weights-improvement-11-2.1606.hdf5\n","Epoch 12/20\n","144331/144331 [==============================] - 159s 1ms/step - loss: 2.1206\n","\n","Epoch 00012: loss improved from 2.16059 to 2.12063, saving model to weights-improvement-12-2.1206.hdf5\n","Epoch 13/20\n","144331/144331 [==============================] - 159s 1ms/step - loss: 2.0817\n","\n","Epoch 00013: loss improved from 2.12063 to 2.08175, saving model to weights-improvement-13-2.0817.hdf5\n","Epoch 14/20\n","144331/144331 [==============================] - 155s 1ms/step - loss: 2.0453\n","\n","Epoch 00014: loss improved from 2.08175 to 2.04532, saving model to weights-improvement-14-2.0453.hdf5\n","Epoch 15/20\n","144331/144331 [==============================] - 155s 1ms/step - loss: 2.0118\n","\n","Epoch 00015: loss improved from 2.04532 to 2.01185, saving model to weights-improvement-15-2.0118.hdf5\n","Epoch 16/20\n","144331/144331 [==============================] - 157s 1ms/step - loss: 1.9813\n","\n","Epoch 00016: loss improved from 2.01185 to 1.98134, saving model to weights-improvement-16-1.9813.hdf5\n","Epoch 17/20\n","144331/144331 [==============================] - 156s 1ms/step - loss: 1.9517\n","\n","Epoch 00017: loss improved from 1.98134 to 1.95169, saving model to weights-improvement-17-1.9517.hdf5\n","Epoch 18/20\n","144331/144331 [==============================] - 157s 1ms/step - loss: 1.9231\n","\n","Epoch 00018: loss improved from 1.95169 to 1.92310, saving model to weights-improvement-18-1.9231.hdf5\n","Epoch 19/20\n","144331/144331 [==============================] - 157s 1ms/step - loss: 1.8988\n","\n","Epoch 00019: loss improved from 1.92310 to 1.89884, saving model to weights-improvement-19-1.8988.hdf5\n","Epoch 20/20\n","144331/144331 [==============================] - 157s 1ms/step - loss: 1.8742\n","\n","Epoch 00020: loss improved from 1.89884 to 1.87417, saving model to weights-improvement-20-1.8742.hdf5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f983f340320>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"q_BU6H1_phwZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"89ed5b9d-f4ce-4abb-cae6-ee8f067e023a","executionInfo":{"status":"ok","timestamp":1563365713007,"user_tz":-120,"elapsed":1926,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}}},"source":["ls"],"execution_count":29,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/                        weights-improvement-11-2.1606.hdf5\n","weights-improvement-01-2.7289.hdf5  weights-improvement-12-2.1206.hdf5\n","weights-improvement-01-2.9591.hdf5  weights-improvement-13-2.0817.hdf5\n","weights-improvement-02-2.6309.hdf5  weights-improvement-14-2.0453.hdf5\n","weights-improvement-03-2.5592.hdf5  weights-improvement-15-2.0118.hdf5\n","weights-improvement-04-2.4963.hdf5  weights-improvement-16-1.9813.hdf5\n","weights-improvement-05-2.4403.hdf5  weights-improvement-17-1.9517.hdf5\n","weights-improvement-06-2.3864.hdf5  weights-improvement-18-1.9231.hdf5\n","weights-improvement-07-2.3367.hdf5  weights-improvement-19-1.8988.hdf5\n","weights-improvement-08-2.2909.hdf5  weights-improvement-20-1.8742.hdf5\n","weights-improvement-09-2.2438.hdf5  wonderland.txt\n","weights-improvement-10-2.1998.hdf5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u1L1Isk0tAUs","colab_type":"text"},"source":["## check that callbacks has stored best models"]},{"cell_type":"code","metadata":{"id":"dut9u1dCU4_8","colab_type":"code","outputId":"13b09f08-ddc9-47bf-8e1f-eac4284de3ff","executionInfo":{"status":"ok","timestamp":1563365736536,"user_tz":-120,"elapsed":1816,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["ls"],"execution_count":30,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/                        weights-improvement-11-2.1606.hdf5\n","weights-improvement-01-2.7289.hdf5  weights-improvement-12-2.1206.hdf5\n","weights-improvement-01-2.9591.hdf5  weights-improvement-13-2.0817.hdf5\n","weights-improvement-02-2.6309.hdf5  weights-improvement-14-2.0453.hdf5\n","weights-improvement-03-2.5592.hdf5  weights-improvement-15-2.0118.hdf5\n","weights-improvement-04-2.4963.hdf5  weights-improvement-16-1.9813.hdf5\n","weights-improvement-05-2.4403.hdf5  weights-improvement-17-1.9517.hdf5\n","weights-improvement-06-2.3864.hdf5  weights-improvement-18-1.9231.hdf5\n","weights-improvement-07-2.3367.hdf5  weights-improvement-19-1.8988.hdf5\n","weights-improvement-08-2.2909.hdf5  weights-improvement-20-1.8742.hdf5\n","weights-improvement-09-2.2438.hdf5  wonderland.txt\n","weights-improvement-10-2.1998.hdf5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PSHIipg-O8Cq","colab_type":"text"},"source":["\n","\n","---\n","\n","## Generating Text with an LSTM Network"]},{"cell_type":"markdown","metadata":{"id":"BgfgxAWcO0Jk","colab_type":"text"},"source":["\n","---\n","\n","## The network weights are loaded from a checkpoint file and the network does not need to be trained."]},{"cell_type":"code","metadata":{"id":"9ZLq6SOWPMTK","colab_type":"code","colab":{}},"source":["# load the network weights\n","filename = \"weights-improvement-20-1.8742.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zesHff1Q2E6e","colab_type":"text"},"source":["---\n","\n","## Finally: make predictions.\n","\n","- ### The simplest way is to first start with a seed sequence as input and predict the next character\n","- ### then update the seed sequence to add the predicted character on the end and trim off the first character.\n","- ### ...repeat this process to predict new characters (e.g. a sequence of 1,000 characters in length).\n"]},{"cell_type":"code","metadata":{"id":"NtHbjyJlQqbE","colab_type":"code","outputId":"7161a083-ebb2-4911-b17f-0927d3bca1c4","executionInfo":{"status":"ok","timestamp":1563365779846,"user_tz":-120,"elapsed":25019,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["import sys\n","\n","#pick a random seed\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print(\"Seed:\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n","print('\\n GENERATE: \\n')\n","\n","# generate characters\n","for i in range(500):\n","  x = np.reshape(pattern, (1, len(pattern), 1))\n","  x = x / float(n_vocab)\n","  prediction = model.predict(x, verbose=0)\n","  index = np.argmax(prediction)\n","  result = int_to_char[index]\n"," \n","  #print every ouput character\n","  sys.stdout.write(result)\n","  \n","  # add output char\n","  pattern.append(index)\n","  # remove first char\n","  pattern = pattern[1:len(pattern)]\n","  \n","print(\"\\nDone.\")"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Seed:\n","\" out loud, and the\n","little thing grunted in reply (it had left off sneezing by this time).\n","'don't grun \"\n","\n"," GENERATE: \n","\n","t to tee it the sooe of the soess siree ' \n","'io yhu a date ranlen a little bick ' said the monk turtle tererke fop i siile th tee to the thrte to tee sha sire the was soink the rame aadirs, and the pere afd the pame ant the was aalut to tee that she had boen her so the tiate tai so tee that she had benne th the thrtg to the thrt har and tored of the tarle thre tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tire tir\n","Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BjSJJA6OVnkK","colab_type":"code","outputId":"5c559c7f-bc57-470f-f290-227c1cc3ee48","executionInfo":{"status":"ok","timestamp":1563365787385,"user_tz":-120,"elapsed":377,"user":{"displayName":"TDVA ETSIT","photoUrl":"","userId":"04493465726705254296"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["result"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'r'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"nO2Tbo852E6g","colab_type":"text"},"source":["# You can look for some ideas and improvements in:\n","\n","- ### [Learn about EMBEDDINGS](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.1-using-word-embeddings.ipynb)\n","\n","- ### [text-generation-lstm-recurrent-neural-networks-python-keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n","\n","- ### [Deepanway Ghosal](https://github.com/deepanwayx/char-and-word-rnn-keras)\n","\n"]}]}